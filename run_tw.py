from __future__ import annotations

import os
import json
import warnings
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import Dict, List, Tuple

import pandas as pd
import requests
from xgboost import XGBRegressor
import pandas_market_calendars as mcal

from utils.market_calendar import is_market_open
from utils.safe_yfinance import safe_yf_download

warnings.filterwarnings("ignore")

# -----------------------------
# Basic settings
# -----------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.join(BASE_DIR, ".cache")
os.makedirs(CACHE_DIR, exist_ok=True)

HISTORY_FILE = os.path.join(BASE_DIR, "tw_history.csv")
TOP300_CACHE_FILE = os.path.join(CACHE_DIR, "top300_tw.json")

WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

# å›ºå®šé¡¯ç¤ºæ¬Šå€¼è‚¡ï¼ˆç…§ä½ åŸæœ¬ï¼‰
FIXED = ["2330.TW", "2317.TW", "2454.TW", "0050.TW", "2308.TW", "2382.TW"]

# -----------------------------
# å°åŠ å›ºåƒæ•¸ï¼ˆç”¨é€”ï¼šåƒè€ƒï¼‰
# -----------------------------
# 5 æ—¥é æ¸¬å ±é…¬é–€æª»ï¼šå¤ªæ¥è¿‘ 0 çš„æ—¥å­ï¼ŒTop5 å„ªå…ˆç”¨é”æ¨™çš„ï¼ˆä¸è¶³ 5 æª”æœƒç”¨å‚™å–è£œæ»¿ï¼‰
MIN_PRED = 0.005   # 0.5%
# è¿‘ 20 æ—¥æ—¥å ±é…¬æ³¢å‹•ä¸Šé™ï¼šé¿å…æ¥µç«¯å¦–è‚¡å¸¸æ…‹éœ¸æ¦œï¼ˆä»æœƒç”¨å‚™å–è£œæ»¿åˆ° 5 æª”ï¼‰
MAX_VOL20 = 0.07   # 7%


# -----------------------------
# Time helpers
# -----------------------------
def _now_tw() -> datetime:
    return datetime.now(ZoneInfo("Asia/Taipei"))


def _today_tw() -> str:
    return _now_tw().strftime("%Y-%m-%d")


def pre_check() -> bool:
    # åªè¦ä¸æ˜¯äº¤æ˜“æ—¥å°±ä¸è·‘ï¼ˆé¿å…ç„¡æ„ç¾©çš„æŠ“è³‡æ–™/è¨“ç·´ï¼‰
    if not is_market_open("TW"):
        print("ğŸ“Œ ä»Šæ—¥éäº¤æ˜“æ—¥ï¼ˆå°è‚¡ä¼‘å¸‚ï¼‰")
        return False
    return True


# -----------------------------
# Finance helpers
# -----------------------------
def calc_pivot(df: pd.DataFrame) -> Tuple[float, float]:
    """è¿‘ 20 æ—¥ Pivot æ”¯æ’/å£“åŠ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    r = df.iloc[-20:]
    h, l, c = float(r["High"].max()), float(r["Low"].min()), float(r["Close"].iloc[-1])
    p = (h + l + c) / 3
    sup = round(2 * p - h, 1)
    res = round(2 * p - l, 1)
    return sup, res


def nth_trading_day_after(start_date: str, n: int, calendar_name: str = "XTAI") -> str:
    """
    å›å‚³ start_date ä¹‹å¾Œç¬¬ n å€‹äº¤æ˜“æ—¥ï¼ˆä¸å« start_date ç•¶å¤©ï¼‰
    ç”¨äº¤æ˜“æ‰€æ—¥æ›†é¿é–‹é€±æœ«/å‡æ—¥
    """
    cal = mcal.get_calendar(calendar_name)
    schedule = cal.schedule(
        start_date=start_date,
        end_date=pd.Timestamp(start_date) + pd.Timedelta(days=60),  # é¿å…é‡åˆ°é•·å‡ä¸å¤ ç”¨
    )
    days = schedule.index.strftime("%Y-%m-%d").tolist()

    if start_date in days:
        pos = days.index(start_date)
        target = pos + n
    else:
        # ç†è«–ä¸Šä¸æœƒç™¼ç”Ÿï¼ˆå› ç‚º pre_check å·²æ“‹éäº¤æ˜“æ—¥ï¼‰
        target = n - 1

    if target >= len(days):
        raise RuntimeError("äº¤æ˜“æ—¥æ›†ä¸è¶³ï¼Œè«‹åŠ å¤§ end_date ç¯„åœ")
    return days[target]


# -----------------------------
# History IO
# -----------------------------
def _read_history() -> pd.DataFrame:
    """
    è®€å– tw_history.csvï¼ˆæ–°æ ¼å¼ï¼‰
    è‹¥ä¸å­˜åœ¨ï¼šå»ºç«‹ç©ºè¡¨ï¼ˆåŒ…å«å®Œæ•´æ¬„ä½ï¼‰
    """
    cols = [
        "run_date",
        "ticker",
        "pred",
        "price_at_run",
        "sup",
        "res",
        "settle_date",
        "settle_close",
        "realized_return",
        "hit",
        "status",
        "updated_at",
    ]

    if not os.path.exists(HISTORY_FILE):
        return pd.DataFrame(columns=cols)

    df = pd.read_csv(HISTORY_FILE)

    # è£œé½Šç¼ºæ¬„ä½ï¼ˆé¿å…èˆŠæª”/ä¸åŒç‰ˆæœ¬ç‚¸æ‰ï¼‰
    for c in cols:
        if c not in df.columns:
            df[c] = pd.NA

    df["status"] = df["status"].fillna("pending")
    df["run_date"] = df["run_date"].astype(str)
    df["ticker"] = df["ticker"].astype(str)
    df["settle_date"] = df["settle_date"].fillna("").astype(str)
    return df


def _write_history(df: pd.DataFrame) -> None:
    df.to_csv(HISTORY_FILE, index=False, encoding="utf-8-sig")


# -----------------------------
# Top300 cache
# -----------------------------
def _load_top300_cache(today: str) -> List[str] | None:
    try:
        with open(TOP300_CACHE_FILE, "r", encoding="utf-8") as f:
            obj = json.load(f)
        if obj.get("date") == today and isinstance(obj.get("tickers"), list):
            return obj["tickers"]
    except Exception:
        pass
    return None


def _save_top300_cache(today: str, tickers: List[str]) -> None:
    try:
        with open(TOP300_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump({"date": today, "tickers": tickers}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def get_top300_by_volume(today: str) -> List[str]:
    """
    å…ˆæŠ“ã€Œä¸Šå¸‚è‚¡ç¥¨æ¸…å–®ã€â†’ ç”¨ yfinance æ‹‰ 1M è³‡æ–™è¨ˆç®—è¿‘ 20 æ—¥å¹³å‡é‡ â†’ å–å‰ 300
    é€™ä¸€æ­¥æœ€å®¹æ˜“è¢« yfinance 429ï¼Œæ‰€ä»¥åšã€Œç•¶æ—¥å¿«å–ã€ï¼šåŒä¸€å¤©å…§é‡è·‘ä¸æœƒå†æŠ“ä¸€è¼ª
    """
    cached = _load_top300_cache(today)
    if cached:
        return cached

    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    html = requests.get(url, timeout=15).text
    table = pd.read_html(html)[0]
    table.columns = table.iloc[0]
    codes = table.iloc[1:][table.columns[0]].astype(str).str.split(" ").str[0]
    tickers = [f"{c}.TW" for c in codes if c.isdigit() and len(c) == 4]

    data = safe_yf_download(tickers, period="1mo", max_chunk=80)

    avg_vol: Dict[str, float] = {}
    for t, d in data.items():
        if d is None or len(d) < 5:
            continue
        v = float(d["Volume"].tail(20).mean())
        if pd.notna(v) and v > 0:
            avg_vol[t] = v

    top300 = sorted(avg_vol, key=avg_vol.get, reverse=True)[:300]
    _save_top300_cache(today, top300)
    return top300


# -----------------------------
# Settlement + stats
# -----------------------------
def settle_history(today: str) -> Tuple[pd.DataFrame, str]:
    """
    çµç®— tw_history.csv è£¡ï¼š
    - status == pending
    - settle_date <= today
    å›å‚³ï¼ˆæ›´æ–°å¾Œ hist, çµç®—æ˜ç´°æ–‡å­—ï¼‰
    """
    hist = _read_history()
    if hist.empty:
        return hist, ""

    # settle_date å…¨ç©ºå°±ä¸ç”¨çµç®—
    if hist["settle_date"].astype(str).str.len().eq(0).all():
        return hist, ""

    pending = hist[
        (hist["status"].astype(str) == "pending")
        & (hist["settle_date"].astype(str) <= today)
        & (hist["settle_date"].astype(str).str.len() > 0)
    ]

    if pending.empty:
        return hist, ""

    tickers = sorted(pending["ticker"].astype(str).unique().tolist())
    data = safe_yf_download(tickers, period="3mo", max_chunk=60)

    settled_lines: List[str] = []
    now_str = _now_tw().strftime("%Y-%m-%d %H:%M:%S")

    for idx, row in pending.iterrows():
        t = str(row["ticker"])
        settle_date = str(row["settle_date"])

        d = data.get(t)
        if d is None or d.empty:
            continue

        d2 = d.copy()
        d2.index = pd.to_datetime(d2.index).strftime("%Y-%m-%d")

        if settle_date not in d2.index:
            continue

        settle_close = float(d2.loc[settle_date, "Close"])
        price_at_run = float(row["price_at_run"])
        rr = (settle_close / price_at_run) - 1.0

        pred = row.get("pred", pd.NA)
        try:
            pred_f = float(pred)
        except Exception:
            pred_f = None

        hit = int(rr > 0)
        mark = "âœ…" if hit == 1 else "âŒ"

        hist.at[idx, "settle_close"] = round(settle_close, 2)
        hist.at[idx, "realized_return"] = rr
        hist.at[idx, "hit"] = hit
        hist.at[idx, "status"] = "settled"
        hist.at[idx, "updated_at"] = now_str

        if pred_f is None:
            settled_lines.append(f"â€¢ {t}: å¯¦éš› {rr:+.2%} {mark}")
        else:
            settled_lines.append(f"â€¢ {t}: é ä¼° {pred_f:+.2%} | å¯¦éš› {rr:+.2%} {mark}")

    if not settled_lines:
        return hist, ""

    # çµç®—æ˜ç´°ï¼šç¶­æŒä½ åŸæœ¬ã€Œåªåˆ—å…§å®¹ã€çš„é¢¨æ ¼ï¼ˆæ¨™é¡Œç”±ä¸»è¨Šæ¯çµ±ä¸€å°ï¼‰
    msg = "\n".join(settled_lines[:10])
    if len(settled_lines) > 10:
        msg += f"\nâ€¦ å¦å¤–é‚„æœ‰ {len(settled_lines) - 10} ç­†å·²çµç®—"

    return hist, msg


def last20_stats_line(hist: pd.DataFrame) -> str:
    """
    ç”¢ç”Ÿï¼š
    æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š65% / å¹³å‡å ±é…¬ï¼š+3.2%
    - åªçœ‹ status==settled ä¸” realized_return æœ‰å€¼
    - ç”¨ settle_date æ’åºï¼ˆåŒæ—¥å¤šç­†ä¹Ÿ OKï¼‰
    """
    if hist is None or hist.empty:
        return "æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š--% / å¹³å‡å ±é…¬ï¼š--%"

    df = hist.copy()
    df = df[df["status"].astype(str) == "settled"]
    df = df[pd.to_numeric(df["realized_return"], errors="coerce").notna()]
    if df.empty:
        return "æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š--% / å¹³å‡å ±é…¬ï¼š--%"

    # æ’åºï¼šå…ˆ settle_dateï¼Œå† updated_atï¼ˆä¿éšªï¼‰
    df["settle_date_sort"] = pd.to_datetime(df["settle_date"], errors="coerce")
    df["updated_at_sort"] = pd.to_datetime(df["updated_at"], errors="coerce")
    df = df.sort_values(by=["settle_date_sort", "updated_at_sort"], ascending=True)

    df20 = df.tail(20)

    hit = pd.to_numeric(df20["hit"], errors="coerce")
    rr = pd.to_numeric(df20["realized_return"], errors="coerce")

    hit_rate = float(hit.mean()) if hit.notna().any() else float("nan")
    avg_rr = float(rr.mean()) if rr.notna().any() else float("nan")

    if not pd.notna(hit_rate) or not pd.notna(avg_rr):
        return "æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š--% / å¹³å‡å ±é…¬ï¼š--%"

    return f"æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š{hit_rate:.0%} / å¹³å‡å ±é…¬ï¼š{avg_rr:+.2%}"


def append_today_predictions(hist: pd.DataFrame, today: str, rows: List[dict]) -> pd.DataFrame:
    if not rows:
        return hist

    now_str = _now_tw().strftime("%Y-%m-%d %H:%M:%S")
    df_new = pd.DataFrame(rows)
    df_new["run_date"] = today
    df_new["status"] = "pending"
    df_new["updated_at"] = now_str

    # é¿å…åŒä¸€å¤©é‡è·‘é‡è¤‡å¯«å…¥ï¼ˆrun_date + tickerï¼‰
    if not hist.empty:
        hist["run_date"] = hist["run_date"].astype(str)
        hist["ticker"] = hist["ticker"].astype(str)
        existing = set(zip(hist["run_date"], hist["ticker"]))
        df_new = df_new[~df_new.apply(lambda r: (today, str(r["ticker"])) in existing, axis=1)]

    if df_new.empty:
        return hist

    return pd.concat([hist, df_new], ignore_index=True)


# -----------------------------
# Discord post
# -----------------------------
def _post(content: str) -> None:
    if WEBHOOK_URL:
        try:
            requests.post(WEBHOOK_URL, json={"content": content}, timeout=15)
        except Exception as e:
            print(f"âš ï¸ Discord ç™¼é€å¤±æ•—: {e}")
            print(content)
    else:
        print(content)


# -----------------------------
# Main
# -----------------------------
def run() -> None:
    today = _today_tw()

    # 1) å…ˆåšæ­·å²çµç®—ï¼ˆåˆ°æœŸçš„è£œä¸Š âœ…/âŒï¼‰
    hist, settle_detail = settle_history(today)

    # 2) ä»Šæ—¥é æ¸¬ï¼ˆTop300 + æ¬Šå€¼ï¼‰
    universe = list(dict.fromkeys(FIXED + get_top300_by_volume(today)))
    data = safe_yf_download(universe, period="2y", max_chunk=60)

    feats = ["mom20", "bias", "vol_ratio"]
    results: Dict[str, dict] = {}

    for s, df in data.items():
        if df is None or len(df) < 160:
            continue

        df = df.copy()
        df["mom20"] = df["Close"].pct_change(20)
        ma20 = df["Close"].rolling(20).mean()
        df["bias"] = (df["Close"] - ma20) / ma20
        df["vol_ratio"] = df["Volume"] / df["Volume"].rolling(20).mean()
        df["target"] = df["Close"].shift(-5) / df["Close"] - 1

        df = df.dropna()
        if len(df) < 120:
            continue

        train = df.iloc[:-1]

        model = XGBRegressor(
            n_estimators=90,
            max_depth=3,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
        )
        model.fit(train[feats], train["target"])

        pred = float(model.predict(df[feats].iloc[-1:])[0])
        sup, res = calc_pivot(df)

        # å°åŠ å›ºï¼šè¿‘ 20 æ—¥æ³¢å‹•ï¼ˆç”¨æ—¥å ±é…¬ stdï¼›è‹¥ä¸è¶³æœƒæ˜¯ nanï¼‰
        vol20 = float(df["Close"].pct_change().rolling(20).std().iloc[-1])

        results[s] = {
            "pred": pred,
            "price": round(float(df["Close"].iloc[-1]), 2),
            "sup": sup,
            "res": res,
            "vol20": vol20,
        }

    if not results:
        _post("âš ï¸ ä»Šæ—¥ç„¡å¯ç”¨çµæœï¼ˆå¯èƒ½è³‡æ–™ä¸è¶³æˆ–æŠ“å–å¤±æ•—ï¼‰")
        return

    # -----------------------------
    # æµ·é¸ Top5ï¼ˆå°åŠ å›ºç‰ˆï¼‰
    # 1) å…ˆæŒ‘ pred é”é–€æª» ä¸” æ³¢å‹•ä¸æ¥µç«¯ çš„ã€Œä¸»é¸ã€
    # 2) ä¸è¶³ 5 æª”ç”¨ã€Œå‚™å–ã€ä¾ pred è£œæ»¿
    # -----------------------------
    items = list(results.items())

    def _vol_ok(v: float) -> bool:
        # vol20 å¯èƒ½æ˜¯ nanï¼›nan è¦–ç‚ºæœªçŸ¥ï¼Œä¸æ“‹ï¼ˆäº¤çµ¦ pred å»æ’åºï¼‰
        try:
            if pd.isna(v):
                return True
            return float(v) <= MAX_VOL20
        except Exception:
            return True

    primary = [
        (t, r) for (t, r) in items
        if (float(r.get("pred", 0.0)) >= MIN_PRED) and _vol_ok(r.get("vol20", float("nan")))
    ]

    primary_set = set([t for (t, _) in primary])
    backup = [(t, r) for (t, r) in items if t not in primary_set]

    primary_sorted = sorted(primary, key=lambda kv: kv[1]["pred"], reverse=True)
    backup_sorted = sorted(backup, key=lambda kv: kv[1]["pred"], reverse=True)

    top = (primary_sorted + backup_sorted)[:5]

    # 3) å¯«å…¥æ­·å²ï¼ˆä»Šæ—¥ Top5ï¼Œä¸¦è¨ˆç®—ç¬¬ 5 å€‹äº¤æ˜“æ—¥çµç®—æ—¥ï¼‰
    new_rows = []
    for t, r in top:
        settle_date = nth_trading_day_after(today, 5, calendar_name="XTAI")
        new_rows.append(
            {
                "ticker": t,
                "pred": r["pred"],
                "price_at_run": r["price"],
                "sup": r["sup"],
                "res": r["res"],
                "settle_date": settle_date,
                "settle_close": pd.NA,
                "realized_return": pd.NA,
                "hit": pd.NA,
            }
        )

    hist = append_today_predictions(hist, today, new_rows)
    _write_history(hist)

    # 4) çµ±è¨ˆï¼ˆæœ€è¿‘ 20 ç­†çµç®—ï¼‰
    stats_line = last20_stats_line(hist)

    # =============================
    # Discord é¡¯ç¤ºï¼šç¶­æŒä½ åŸæœ¬æ ¼å¼
    # =============================
    msg = f"ğŸ“Š å°è‚¡ AI é€²éšé æ¸¬å ±å‘Š ({today})\n"
    msg += "-" * 42 + "\n\n"

    # --- Top 5 ---
    msg += "ğŸ† AI æµ·é¸ Top 5 (æ½›åŠ›è‚¡)\n"
    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ“ˆ", "ğŸ“ˆ"]
    for i, (t, r) in enumerate(top):
        msg += f"{medals[i]} {t}: é ä¼° {r['pred']:+.2%}\n"
        msg += f" â”” ç¾åƒ¹: {r['price']} (æ”¯æ’: {r['sup']} / å£“åŠ›: {r['res']})\n"

    # --- Fixed large-cap stocks ---
    msg += "\nğŸ’ æŒ‡å®šæ¬Šå€¼è‚¡ç›£æ§ (å›ºå®šé¡¯ç¤º)\n"
    for t in FIXED:
        if t not in results:
            continue
        r = results[t]
        msg += f"{t}: é ä¼° {r['pred']:+.2%}\n"
        msg += f" â”” ç¾åƒ¹: {r['price']} (æ”¯æ’: {r['sup']} / å£“åŠ›: {r['res']})\n"

    # --- Settlement ---
    msg += "\nğŸ å°è‚¡ 5 æ—¥å›æ¸¬çµç®—å ±å‘Š\n"
    if settle_detail.strip():
        msg += settle_detail + "\n"

    # --- Stats line you asked (always shown, even if no settlements yet) ---
    msg += f"\n{stats_line}\n"

    msg += "\nğŸ’¡ AI ç‚ºæ©Ÿç‡æ¨¡å‹ï¼Œåƒ…ä¾›ç ”ç©¶åƒè€ƒ"

    _post(msg[:1900])


if __name__ == "__main__":
    if pre_check():
        run()
