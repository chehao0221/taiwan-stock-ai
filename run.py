import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
from xgboost import XGBRegressor
import warnings
import os

warnings.filterwarnings("ignore")

DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")

# ====== è¨­å®šå€ ======
YEARS = 3
TOP_PICK = 5
MIN_VOLUME = 500000 
# é€™è£¡å®šç¾©æ‚¨çš„å¿…çœ‹åå–®
MUST_WATCH = ["2330.TW", "2317.TW", "00919.TW", "0050.TW", "00991A.TW"] 

# ====== 1. æŠ“å–æ¸…å–® ======
def get_combined_list():
    try:
        url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
        res = requests.get(url)
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df.iloc[1:]
        symbols = []
        for index, row in df.iterrows():
            cfi = str(row['CFICode'])
            if cfi.startswith('ES') or cfi.startswith('CE'):
                code = row['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].split('\u3000')[0]
                symbols.append(code + ".TW")
        # çµåˆå¿…çœ‹åå–®èˆ‡å‰500æª”
        return list(set(symbols[:500] + MUST_WATCH))
    except:
        return MUST_WATCH

# ====== 2. æŠ€è¡“æŒ‡æ¨™ ======
def compute_features(df):
    df["mom20"] = df["Close"].pct_change(20)
    df["mom60"] = df["Close"].pct_change(60)
    delta = df["Close"].diff()
    up = delta.clip(lower=0).rolling(14).mean()
    down = (-delta.clip(upper=0)).rolling(14).mean()
    df["rsi"] = 100 - (100 / (1 + up / (down + 1e-9)))
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)
    df["volatility"] = df["Close"].pct_change().rolling(20).std()
    return df

# ====== 3. ä¸»æµç¨‹ ======
def run():
    symbols = get_combined_list()
    data = yf.download(symbols, period=f"{YEARS}y", progress=False)
    
    scoring = [] # å­˜å„² Top Pick
    must_watch_results = [] # å­˜å„²å¿…çœ‹åå–®çµæœ
    analyzed_count = 0
    features = ["mom20", "mom60", "rsi", "vol_ratio", "volatility"]

    for sym in symbols:
        try:
            df = data.xs(sym, axis=1, level=1).dropna(how='all') if len(symbols) > 1 else data.dropna(how='all')
            if len(df) < 250: continue
            
            analyzed_count += 1
            df = compute_features(df)
            df["future_return"] = df["Close"].shift(-5) / df["Close"] - 1
            full_data = df.dropna()
            
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.07, random_state=42)
            model.fit(full_data[features], full_data["future_return"])
            
            pred = model.predict(df[features].iloc[-1:])[0]
            
            res_item = (sym, pred)
            # å¦‚æœåœ¨å¿…çœ‹åå–®ä¸­ï¼Œå–®ç¨è¨˜éŒ„
            if sym in MUST_WATCH:
                must_watch_results.append(res_item)
            # å¦‚æœæµå‹•æ€§é”æ¨™ï¼ŒåŠ å…¥å…¨å¸‚å ´æ’å
            if df["Volume"].tail(20).mean() >= MIN_VOLUME:
                scoring.append(res_item)
        except: continue

    # æ’åº
    scoring = sorted(scoring, key=lambda x: x[1], reverse=True)[:TOP_PICK]
    
    # ç™¼é€ Discord
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    msg = f"ğŸŒŸ **AI å…¨å¸‚å ´æƒæå ±è¡¨** ({today})\n"
    msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    msg += "ğŸ† **æœªä¾† 5 æ—¥çœ‹æ¼²æ’è¡Œæ¦œ**\n"
    for i, (s, p) in enumerate(scoring):
        msg += f"{['ğŸ¥‡','ğŸ¥ˆ','ğŸ¥‰','ğŸ“ˆ','ğŸ“ˆ'][i]} **{s}**: `+{p:.2%}`\n"
    
    msg += "\nğŸ” **æŒ‡å®šæ¨™çš„è¿½è¹¤**\n"
    for s, p in must_watch_results:
        status = "ğŸ”¥" if p > 0.01 else "ğŸ’" if p > 0 else "â˜ï¸"
        msg += f"{status} **{s}**: `+{p:.2%}`\n"
    
    msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    requests.post(DISCORD_WEBHOOK_URL, json={"content": msg})
    print("âœ… å ±è¡¨å·²æˆåŠŸç™¼é€")

if __name__ == "__main__":
    run()
